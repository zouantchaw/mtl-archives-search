# Search Guide

A comprehensive guide to searching the Montreal Archives photo collection.

## Overview

The search interface offers three modes, each optimized for different types of queries:

| Mode | Best For | How It Works |
|------|----------|--------------|
| **Visual** | Single concepts, objects, scenes | Client-side CLIP matches your query against image features |
| **Text** | Descriptive queries, time periods, context | Server-side BGE matches against VLM-generated captions |
| **Hybrid** | General purpose, balanced results | Combines both with smart weighting |

---

## Visual Mode (CLIP)

### How It Works

1. Your query is converted to a 512-dimensional vector using CLIP (runs in your browser)
2. This vector is compared against pre-computed image embeddings
3. Results are ranked by visual similarity

### When to Use

- **Single-word visual concepts**: objects, buildings, scenes
- **When you know what it looks like** but not how to describe it
- **Visual similarity searches**: "find more like this"

### Example Queries

| Query | Why It Works Well |
|-------|-------------------|
| `church` | CLIP understands the visual concept of a church |
| `bridge` | Distinct visual structure, easy for CLIP to match |
| `snow` | Visual texture/pattern recognition |
| `crowd` | CLIP recognizes groups of people |
| `aerial view` | Distinct perspective, trained on many examples |
| `horse` | Animals have strong visual signatures |
| `construction` | Scaffolding, cranes, workers - visual patterns |
| `train` | Locomotives have distinctive shapes |
| `waterfront` | Water + buildings = recognizable scene |

### Less Effective Queries

| Query | Why It Struggles |
|-------|------------------|
| `1940s` | Time periods aren't visually distinct |
| `Montreal` | Location isn't visible in most photos |
| `historical` | Abstract concept, not visual |
| `rare photograph` | Subjective, not a visual feature |

### Pro Tips

- **Be specific about objects**: "red car" > "vehicle"
- **Describe the scene type**: "street corner" > "urban"
- **Use visual adjectives**: "tall building", "crowded street", "empty park"

---

## Text Mode (Semantic/BGE)

### How It Works

1. Your query is sent to the server
2. It's converted to a 1024-dimensional vector using BGE (Workers AI)
3. This vector is compared against embeddings of VLM-generated image captions
4. Results are ranked by semantic text similarity

### When to Use

- **Longer, descriptive queries** that match caption style
- **Time-based searches**: decades, specific years
- **Context that isn't visible**: location names, historical context
- **When Visual mode isn't finding what you need**

### Example Queries

| Query | Why It Works Well |
|-------|-------------------|
| `black and white photograph of a snowy street` | Matches caption description style |
| `archival photo from the 1940s` | Captions often mention dates |
| `building with a clock tower` | Specific architectural detail mentioned in captions |
| `street scene with vintage cars` | Descriptive phrase matching |
| `photograph showing construction workers` | Activity description |
| `aerial photograph of downtown` | Matches caption terminology |
| `historic image of a park with trees` | Descriptive scene matching |
| `old photograph of a residential neighborhood` | Context + scene type |

### Less Effective Queries

| Query | Why It Struggles |
|-------|------------------|
| `church` | Too short; captions might say "building with steeple" instead |
| `pretty` | Subjective; VLM captions are factual |
| `interesting photo` | Not descriptive of content |
| `best images` | Quality judgments aren't in captions |

### Pro Tips

- **Write like a caption**: "The image shows a..." style queries work well
- **Include context words**: "historical", "archival", "photograph"
- **Be descriptive**: "large stone building" > "building"
- **Mention time if relevant**: "dated 1950s", "early 20th century"

### Understanding VLM Captions

The captions were generated by an AI (LLaVA) and follow patterns like:

> "The image is a black and white photograph of a city street. The street is lined with tall buildings and there are several cars parked along the curb. The scene appears to be from the mid-20th century based on the style of the vehicles."

Queries that match this style work best.

---

## Hybrid Mode

### How It Works

1. Runs both Visual (CLIP) and Text (BGE) searches in parallel
2. Combines results with dynamic weighting based on query length:

| Query Length | CLIP Weight | Text Weight |
|--------------|-------------|-------------|
| 1-2 words | 80% | 20% |
| 3-4 words | 60% | 40% |
| 5+ words | 40% | 60% |

3. Results appearing in both searches get boosted scores
4. Final ranking reflects the combined relevance

### When to Use

- **Default choice** when you're not sure which mode is best
- **Mixed queries** with both visual and contextual elements
- **Exploratory searches** when you want diverse results

### Example Queries

| Query | Weighting | Expected Behavior |
|-------|-----------|-------------------|
| `church` | 80% CLIP | Mostly visual results, like Visual mode |
| `old stone church` | 60% CLIP | Visual dominates, but text helps filter |
| `historic photograph of a church in winter` | 40% CLIP | Text matching becomes more important |
| `snowy street` | 80% CLIP | Visual snow detection + street scene |
| `black and white photo of children playing` | 40% CLIP | Descriptive query favors text matching |

### Pro Tips

- **Start with Hybrid**, then switch to Visual or Text if results aren't good
- **Short queries** in Hybrid behave like Visual mode
- **Long queries** in Hybrid behave like Text mode
- **Results in both** searches appear higher (boosted by appearing twice)

---

## Query Comparison Examples

### Example 1: Finding Churches

| Mode | Query | Result Quality | Notes |
|------|-------|----------------|-------|
| Visual | `church` | Excellent | CLIP recognizes church architecture |
| Text | `church` | Fair | Captions might say "building with steeple" |
| Text | `photograph of a church with a tall steeple` | Good | Matches caption style |
| Hybrid | `church` | Excellent | 80% CLIP weight saves it |

**Recommendation**: Use **Visual** for `church`

### Example 2: Finding Winter Scenes

| Mode | Query | Result Quality | Notes |
|------|-------|----------------|-------|
| Visual | `snow` | Excellent | Visual texture recognition |
| Visual | `winter` | Good | Less specific than "snow" |
| Text | `snowy street scene` | Good | Matches caption descriptions |
| Hybrid | `snow` | Excellent | CLIP dominates |

**Recommendation**: Use **Visual** for `snow`, **Text** for `snowy street in the 1950s`

### Example 3: Finding Photos from a Specific Era

| Mode | Query | Result Quality | Notes |
|------|-------|----------------|-------|
| Visual | `1940s` | Poor | Decades aren't visual |
| Text | `photograph from the 1940s` | Good | Captions include dates |
| Text | `dated 1947` | Excellent | Specific year matching |
| Hybrid | `old cars from the 1940s` | Good | Visual cars + text date |

**Recommendation**: Use **Text** for time-based queries

### Example 4: Finding Specific Architecture

| Mode | Query | Result Quality | Notes |
|------|-------|----------------|-------|
| Visual | `art deco building` | Good | Recognizes style |
| Visual | `skyscraper` | Excellent | Distinctive shape |
| Text | `tall building with ornate facade` | Good | Descriptive match |
| Hybrid | `art deco skyscraper` | Excellent | Both contribute |

**Recommendation**: Use **Hybrid** for architectural queries

### Example 5: Finding People and Activities

| Mode | Query | Result Quality | Notes |
|------|-------|----------------|-------|
| Visual | `crowd` | Excellent | Visual pattern |
| Visual | `workers` | Good | People in work context |
| Text | `construction workers on scaffolding` | Good | Specific activity |
| Hybrid | `people walking on street` | Good | Common scene |

**Recommendation**: Use **Visual** for people, **Text** for specific activities

---

## Troubleshooting

### "I'm not finding what I want"

1. **Try a different mode**: If Visual isn't working, try Text (or vice versa)
2. **Rephrase your query**:
   - Visual: Use concrete nouns ("bridge", "car", "tree")
   - Text: Use descriptive phrases ("photograph showing...", "image of a...")
3. **Check spelling**: Typos affect Text mode more than Visual
4. **Be more/less specific**: Sometimes "building" works better than "office building"

### "Results don't match my query"

- **Visual mode**: CLIP might be matching unexpected visual features. Try more specific terms.
- **Text mode**: Your query might not match how captions are written. Try caption-style phrasing.
- **Hybrid mode**: Try switching to pure Visual or Text to see which is causing issues.

### "Same images appearing multiple times"

This is a known issue with some duplicate records in the database. The images are the same, just indexed twice.

### "Image not found"

About 4% of images are missing from storage. These are records where the original image couldn't be retrieved from Montreal's servers.

---

## Quick Reference Card

```
VISUAL MODE (CLIP)
  Best: church, bridge, snow, crowd, aerial, train
  Avoid: 1940s, Montreal, historical, rare

TEXT MODE (BGE)
  Best: "black and white photo of...", "dated 1950", "building with..."
  Avoid: Single words, subjective terms

HYBRID MODE
  Short queries (1-2 words) → 80% Visual
  Medium queries (3-4 words) → 60% Visual
  Long queries (5+ words) → 60% Text
```

---

## Technical Details

For developers and curious users:

- **CLIP Model**: `clip-vit-base-patch32` (512 dimensions), runs client-side via Xenova/transformers
- **BGE Model**: `bge-large-en-v1.5` (1024 dimensions), runs server-side via Cloudflare Workers AI
- **VLM Captions**: Generated by LLaVA 1.5 7B, describing image content in 2-3 sentences
- **Index Size**: 14,822 images with embeddings
- **Caption Coverage**: 98% of images have VLM-generated captions

See [architecture.md](./architecture.md) for full technical documentation.
